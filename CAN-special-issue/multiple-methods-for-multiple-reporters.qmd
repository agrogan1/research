---
title: "Multiple Methods for Multiple Reporters of Child Maltreatment"
subtitle: "Results from the Lehigh Study"
author: "Lehigh Measurement and Causal Inference Analyses Team"
date: "today"
format:
  html: 
    toc: true
    number-sections: true
    theme: yeti
    lightbox: true
  typst: 
    toc: true
    number-sections: true
  docx: 
    toc: true
    number-sections: true
editor: source
---

# Background

```{r}
#| echo: false
#| message: false
#| output: false

library(Statamarkdown)

```


The Lehigh Study presents a unique opportunity. Data are collected on experiences of abusive discipline as reported by *administrative* reports, two *parental* reports at two different time points, and two *self* reports at two different time points. However, in the absence of a gold standard measure of abusive discipline, appropriately aggregating these multiple reports across multiple time points represents an analytic challenge.

In the manuscript below, we employ multiple strategies to estimate the relationship of these multiple reports from multiple reporters at multiple time points to a mental health outcome. We compare and contrast the advantages and disadvantages of these different methods, and conclude the manuscript with suggestions on optimal methodological approaches to confront the methodological challenges that are posed by having multiple reports from multiple reporters at multiple time points. 

# Basic Conceptual Model

We begin with a basic conceptual model of the reports and time points in the data, without at this point suggesting any associational or causal relationships. 

![conceptual model](Slide1.png){#fig-conceptual}

# Variable Abbreviations

For parsimony, we use the following conventions for variable names in equations and statistical syntax.

| Variable          | Label                               |
|-------------------|:------------------------------------|
| `administrative`  | administrative report               |
| `PR1`             | parental report in early childhood  |
| `PR2`             | parental report in middle childhood |
| `SR1`             | adolescent self report              |
| `SR2`             | adult self report                   |
| `covariates`      | covariates (multiple variables)     |
| `outcome`         | mental health outcome               |

: Variables and Variable Labels {#tbl-variables}

# Methods

## OLS Regression

Our outcome is continuous. Therefore we here employ *ordinary least squares regression*. Were our outcome to be dichotomous, we could as easily employ *logistic regression*. 

### Diagram

![OLS](Slide2.png){#fig-OLS}

### Equation

$$\text{outcome} = \beta_0 + \beta \text{P1} + \beta \text{P2} + \beta \text{SR1} + \beta \text{SR2} + \beta \text{administrative} + \Sigma \beta \text{covariates} + e_i$$ {#eq-OLS}

### Syntax   

```{stata}
#| eval: false

regress outcome P1 P2 SR1 SR2 administrative covariates

```

For logistic regression, the appropriate syntax would be:  

```{stata}
#| eval: false

logit outcome P1 P2 SR1 SR2 administrative covariates, or

```

## Summing Across Reporters

### Diagram

![summing across reporters](Slide3.png){#fig-sum}

### Equation

First, we average parental reports:

$$P = \frac{P1 + P2}{2}$$ {#eq-average-parental}

Then, we average self reports: 

$$SR = \frac{SR1 + SR2}{2}$$ {#eq-average-self}

Lastly, we estimate an OLS model in which averaged parental and self reports are variables in the model. 

$$\text{outcome} = \beta_0 + \beta \text{P} + \beta \text{SR} + \beta \text{administrative} + \Sigma \beta \text{covariates} + e_i$$ {#eq-average-reporters}

### Syntax

```{stata}
#| eval: false

generate P = (P1 + P2) / 2 // is averaging appropriate?
  
generate SR = (SR1 + SR2) / 2 // is averaging appropriate?

regress outcome P SR administrative covariates

```

## Path Model

### Diagram

![path model](Slide4.png){#fig-path}

### Equation

$$\text{outcome} = \beta_0 + \beta \text{P1} + \beta \text{P2} + \beta \text{SR1} + \beta \text{SR2} + \beta \text{administrative} + \Sigma \beta \text{covariates} + e_i$$ {#eq-path}

$$\text{SR2} = \beta_0 + \beta \text{SR1} + e_i$$
$$\text{P2} = \beta_0 + \beta \text{P1} + e_i$$

### Syntax

```{stata}
#| eval: false

sem (outcome <- covariates SR1 SR2 PR1 PR2 administrative) ///
  (SR2 <- SR1) ///
  (PR2 <- PR1) ///
  cov(e.outcome*e.SR2*e.PR2) // correlated errors

```

## Latent Construct(s)

### Diagram

![latent construct](Slide5.png){#fig-latent-construct}


### Equation

### Syntax

```{stata}
#| eval: false

sem ///
  (P1 P2 SR1 SR2 administrative <- X) /// measurement
  (outcome <- covariates X) // structural

```

## Latent Profile Analysis (Person Centered Approach)

### Diagram

![latent profile](Slide6.png){#fig-latent-profile}



### Equation

### Syntax

We first run a latent class analysis to generate latent underlying classes based upon the reports of discipline from the different reporterers 

In the syntax below, we estimate three latent classes. The actual number of latent classes is determined by running models with different numbers of latent classes, and comparing those models using *fit statistics*, and *likelihood ratio tests*. 

```{stata}
#| eval: false

gsem (P1 P2 SR1 SR2 administrative <-, gaussian), (lclass(C 3))

```

We then use class membership to predict the outcome.

```{stata}
#| eval: false

regress outcome i.class covariates

```

## Network Analysis

### Diagram

![network model](Slide7.png){#fig-network}


### Equation

$$\begin{matrix}
& \text{P1} & \text{P2} & \text{SR1} & \text{SR2} & \text{administrative} & \text{outcome} \\
\text{P1} & 1 & r_{\text{P1, P2}} & r_{\text{P1, SR1}} & r_{\text{P1, SR2}} & r_{\text{P1, administrative}} & r_{\text{P1, outcome}} \\ 
\text{P2} & & 1 & r_{\text{P2, SR1}} & r_{\text{P2, SR2}} & r_{\text{P2, administrative}} & r_{\text{P2, outcome}}\\
\text{SR1} & & & 1 & r_{\text{SR1, SR2}} & r_{\text{SR1, administrative}} & r_{\text{SR1, outcome}}\\
\text{SR2} & & & & 1 & r_{\text{SR2, administrative}} & r_{\text{SR2, outcome}}\\
\text{administrative} & & & & & 1 & r_{\text{administrative, outcome}}\\ \\
\text{outcome} & & & & & & 1
\end{matrix}$$ {#eq-network-matrix}

### Syntax

```{stata}
#| eval: false

corr P1 P2 SR1 SR2 administrative outcome

```

## ~~Multilevel Modeling~~

## ~~Classification and Regression Tree (CART) (Machine Learning)~~

## ~~Random Forest (Machine Learning)~~









